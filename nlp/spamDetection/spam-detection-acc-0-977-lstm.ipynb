{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc3ca4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.43896,
     "end_time": "2024-09-11T11:42:23.715473",
     "exception": false,
     "start_time": "2024-09-11T11:42:23.276513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018aac0b-7f03-4f8a-a20a-1b299eb7aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff02ca",
   "metadata": {
    "papermill": {
     "duration": 13.766752,
     "end_time": "2024-09-11T11:42:37.487320",
     "exception": false,
     "start_time": "2024-09-11T11:42:23.720568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ede48",
   "metadata": {
    "papermill": {
     "duration": 1.318214,
     "end_time": "2024-09-11T11:42:38.810991",
     "exception": false,
     "start_time": "2024-09-11T11:42:37.492777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "hyperparams = {\n",
    "    'vocab_size' : 1000,\n",
    "    'dim' : 30,\n",
    "    'max_len' : 515\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82ca75",
   "metadata": {
    "papermill": {
     "duration": 0.913925,
     "end_time": "2024-09-11T11:42:39.729997",
     "exception": false,
     "start_time": "2024-09-11T11:42:38.816072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "# ! unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094bacb",
   "metadata": {
    "papermill": {
     "duration": 0.064039,
     "end_time": "2024-09-11T11:42:39.799238",
     "exception": false,
     "start_time": "2024-09-11T11:42:39.735199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/spamDetection/spam.csv\", encoding='latin1')\n",
    "data = data.loc[:, ['v1', 'v2']]\n",
    "data = data.rename(columns={'v1': 'label', 'v2': 'message'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f9338",
   "metadata": {
    "papermill": {
     "duration": 0.662416,
     "end_time": "2024-09-11T11:42:40.466820",
     "exception": false,
     "start_time": "2024-09-11T11:42:39.804404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db2966",
   "metadata": {
    "papermill": {
     "duration": 0.005213,
     "end_time": "2024-09-11T11:42:40.478819",
     "exception": false,
     "start_time": "2024-09-11T11:42:40.473606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc54718",
   "metadata": {
    "papermill": {
     "duration": 0.016784,
     "end_time": "2024-09-11T11:42:40.502017",
     "exception": false,
     "start_time": "2024-09-11T11:42:40.485233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = data['label']\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdf55a",
   "metadata": {
    "papermill": {
     "duration": 0.00522,
     "end_time": "2024-09-11T11:42:40.512797",
     "exception": false,
     "start_time": "2024-09-11T11:42:40.507577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Clean X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272fe43",
   "metadata": {
    "papermill": {
     "duration": 0.019091,
     "end_time": "2024-09-11T11:42:40.537393",
     "exception": false,
     "start_time": "2024-09-11T11:42:40.518302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_message(message, method):\n",
    "    \n",
    "    def semmatize_msg():\n",
    "        return [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    def lemmatize_msg():\n",
    "        return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    def lemmatize_pos_msg():\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        return [\n",
    "            lemmatizer.lemmatize(word, pos='v' if tag.startswith('V') else 'n' if tag.startswith('N') else 'a' if tag.startswith('J') else 'r' if tag.startswith('R') else 'n')\n",
    "            for word, tag in pos_tags\n",
    "        ]\n",
    "    \n",
    "    # Lowercase the message\n",
    "    message = message.lower()\n",
    "    \n",
    "    # Remove everything except letters\n",
    "    message = re.sub(r'[^a-z\\s]', '', message)\n",
    "    \n",
    "    # Tokenize the message\n",
    "    tokens = nltk.word_tokenize(message)\n",
    "    \n",
    "    # Remove single character words and stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if len(word) > 1 and word not in stop_words]\n",
    "    \n",
    "    # Apply the selected method for word processing\n",
    "    if method == 'stem':\n",
    "        processed_tokens = semmatize_msg()\n",
    "    elif method == 'lemmatize':\n",
    "        processed_tokens = lemmatize_msg()\n",
    "    elif method == 'lemmatize_pos':\n",
    "        processed_tokens = lemmatize_pos_msg()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose from 'stem', 'lemmatize', or 'lemmatize_pos'.\")\n",
    "    \n",
    "    # Join the tokens back into a single string\n",
    "    cleaned_message = ' '.join(processed_tokens)\n",
    "\n",
    "    return cleaned_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63760e21",
   "metadata": {
    "papermill": {
     "duration": 3.143026,
     "end_time": "2024-09-11T11:42:43.685996",
     "exception": false,
     "start_time": "2024-09-11T11:42:40.542970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data['message'].apply(lambda x: clean_message(x, method='stem'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fc890",
   "metadata": {
    "papermill": {
     "duration": 0.005342,
     "end_time": "2024-09-11T11:42:43.697125",
     "exception": false,
     "start_time": "2024-09-11T11:42:43.691783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311194f",
   "metadata": {
    "papermill": {
     "duration": 0.018532,
     "end_time": "2024-09-11T11:42:43.721221",
     "exception": false,
     "start_time": "2024-09-11T11:42:43.702689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765e64f",
   "metadata": {
    "papermill": {
     "duration": 0.005385,
     "end_time": "2024-09-11T11:42:43.732463",
     "exception": false,
     "start_time": "2024-09-11T11:42:43.727078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preproces X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ae4ac",
   "metadata": {
    "papermill": {
     "duration": 0.153054,
     "end_time": "2024-09-11T11:42:43.891040",
     "exception": false,
     "start_time": "2024-09-11T11:42:43.737986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = hyperparams['vocab_size'])\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "def prepare_input(inputx):\n",
    "    seq_docs = tokenizer.texts_to_sequences(inputx)\n",
    "    padded_docs = pad_sequences(seq_docs, padding='pre', maxlen=hyperparams['max_len'])\n",
    "    return padded_docs\n",
    "\n",
    "X_train = prepare_input(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3ea6a",
   "metadata": {
    "papermill": {
     "duration": 0.005381,
     "end_time": "2024-09-11T11:42:43.902209",
     "exception": false,
     "start_time": "2024-09-11T11:42:43.896828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2c35c",
   "metadata": {
    "papermill": {
     "duration": 0.183636,
     "end_time": "2024-09-11T11:42:44.091384",
     "exception": false,
     "start_time": "2024-09-11T11:42:43.907748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "            keras.layers.Embedding(hyperparams['vocab_size'], hyperparams['dim'], input_shape=(hyperparams['max_len'], )),\n",
    "            keras.layers.LSTM(256),\n",
    "            keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef55bb8",
   "metadata": {
    "papermill": {
     "duration": 0.006362,
     "end_time": "2024-09-11T11:42:44.104478",
     "exception": false,
     "start_time": "2024-09-11T11:42:44.098116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f443f577",
   "metadata": {
    "papermill": {
     "duration": 512.196415,
     "end_time": "2024-09-11T11:51:16.307888",
     "exception": false,
     "start_time": "2024-09-11T11:42:44.111473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a785e8c",
   "metadata": {
    "papermill": {
     "duration": 0.023944,
     "end_time": "2024-09-11T11:51:16.353780",
     "exception": false,
     "start_time": "2024-09-11T11:51:16.329836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c4171",
   "metadata": {
    "papermill": {
     "duration": 17.673303,
     "end_time": "2024-09-11T11:51:34.049257",
     "exception": false,
     "start_time": "2024-09-11T11:51:16.375954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = prepare_input(X_test)\n",
    "acc = model.evaluate(X_test, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b2e70",
   "metadata": {
    "papermill": {
     "duration": 0.025533,
     "end_time": "2024-09-11T11:51:34.100653",
     "exception": false,
     "start_time": "2024-09-11T11:51:34.075120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 483,
     "sourceId": 982,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 555.305311,
   "end_time": "2024-09-11T11:51:35.853231",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-11T11:42:20.547920",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
